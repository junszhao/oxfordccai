---
title: Children and genAI (JUST LAUNCHED)
date: 2024-07-18
image:
  focal_point: 'top'
authors:
  - Jun Zhao
---


Oxford CCAI is launching a new research study on understanding children's perception of generative AI, between May and September 2025.

## <font color="blue">Your help is needed!</font>

A recent survey shows that **79% of children aged 13-17** are now *using* generative AI technologies, and **40% of children aged 7-12** are also *adopting* them. SnapchatMyAI is the most popular AI tool among kids aged 13-17, though ChatGPT is the most commonly used by those aged 16 and older. 

According to another report, children between the ages of 11 and 17 are primarily using AI tools like ChatGPT out of curiosity, for help with homework, to solve problems, find information, have fun, or to learn something new. Meanwhile, those using SnapchatMyAI are mostly motivated by a desire to have fun (50%) or try out the tool (39%).


While these surveys shed light on why children are using these technologies, we don’t know much about how they experience them. Do children feel respected by AI tools? Do they believe the technology is fair, trustworthy, and enjoyable? Would they like more support to better understand the results they get from these tools, feel more respected, and have more opportunities to express their preferences about how these technologies respond to their needs and queries?

> Do children feel respected by AI tools? 

> Do they believe the technology is fair, trustworthy, and enjoyable? 

> Would they like more support to better understand the results they get from these tools, feel more respected, and have more opportunities to express their preferences about how these technologies respond to their needs and queries?

> --- Questions asked by the new OxfordCCAI research study (05-09.2025)


To answer these questions, we will visit UK schools and talk to children aged 13 to 17. 


## Our study and method

We plan to recruit around 500 children aged 13-15 and 15-17 from schools across the UK, with a total of approximately 1,000 participants.

Our goal is for the study participants to represent the national demographics. This includes ensuring an equal distribution of gender and a proportionate number of students eligible for free school meals (FSM), in line with UK national statistics.


## How it may benefit pupils and schools

We will present this study as a potential learning experience for children and invite participating schools to incorporate it into their classroom activities or use it to supplement their lessons.

We will ensure that no personally identifiable information is collected during the study, and no such information will be shared with school teachers. Teachers will only receive summary information to help guide their follow-up lessons.

## What will happen in the study

The study consists of two parts for each participant:
- Completing an online survey; 
- Completing three tasks by interacting with four AI (large language) models.

Both the survey and the tasks are designed to take no more than 30 minutes in total, making it easy to fit into a classroom schedule. The survey allows us to collect participants' *stated* preferences, while the tasks help us verify these preferences by seeing how they express themselves when completing the tasks.


**We are happy to arrange introductory video calls or meetings with teachers before agreeing to participate, and we can tailor support to help schools teach about generative AI whenever possible**.

The short online survey will ask participants to share:
1. How familiar they are with large language models (LLMs)
2. Their own expectations for LLM characteristics, such as honesty, accuracy, friendliness, etc.
3. Their preferences for LLM behaviour, such as being accurate, trustworthy, fair, fun, creative, etc.
4. Basic demographic information, such as age, gender, and eligibility for free school meals (FSM).


For the task part of the study, participants will complete three types of tasks:
- Solving a problem
- Finding information or learning about something
- Discussing something important to them, like family, friendship, culture, music, etc.


These tasks were selected based on a recent report that highlights the most common tasks children use LLMs for.

For each task, participants will <font color="green">type a free-text prompt</font> into the experiment interface and receive responses from four different LLM models: ChatGPT, BingChat, DALL-E, and Claude. These models were chosen because they have a minimum age requirement of 13 and can all be accessed through an API.


Participants will be reminded at the start and throughout the study to <font color="red">avoid sharing personal information that could identify them</font>, as the study will create a public dataset that can be used to build child-friendly LLMs or evaluate existing ones.


After completing each task, participants will <font color="green">rate the response they received from each LLM</font> and choose which model best aligns with their values (e.g., accuracy, trustworthiness, fairness, fun, creativity). This information will be compared with their stated preferences from the survey.

Once all three tasks are completed, participants will have the opportunity to <font color="green">give open-ended feedback</font> on their experience with the models and the study.




## Are there any benefits and risks in taking part?

We hope this study will help participants learn more about generative AI and how to use it effectively, with potential benefits for other children in the future.

We’ve taken steps to ensure participants' safety. Only basic information like age, gender, and socio-economic status will be collected for research purposes, and it won’t be shared with anyone.

All data will be stored securely at the University of Oxford. Any personal information will be deleted once it's no longer needed, and only the research team will have access, with data labeled by participant ID rather than name.


# Data Protection

The University of Oxford is the data controller for participants' personal data and will determine how this data is used in the research.

The University will process participants' personal data solely for the purpose of this research, which is conducted in the public interest.

For more information about your rights regarding personal data, please visit[https://compliance.web.ox.ac.uk/individual-rights](https://compliance.web.ox.ac.uk/individual-rights).


# Who has reviewed this research?
This research has received ethics approval from a subcommittee of the University of Oxford Central University Research Ethics Committee. 


# What if there is a problem or something goes wrong?

For any questions, please contact the researcher via (oxfordccai@cs.ox.ac.uk).  




Thank you for reading – please ask any questions.
